{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi =False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7613, 5), (3263, 4), (10876, 5))"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "\n",
    "df = pd.concat([df_train,df_test], axis=0)\n",
    "df_train.shape, df_test.shape , df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location  target  \\\n",
       "0   1     NaN      NaN     1.0   \n",
       "1   4     NaN      NaN     1.0   \n",
       "2   5     NaN      NaN     1.0   \n",
       "3   6     NaN      NaN     1.0   \n",
       "4   7     NaN      NaN     1.0   \n",
       "\n",
       "                                                text  \n",
       "0  Our Deeds are the Reason of this #earthquake M...  \n",
       "1             Forest fire near La Ronge Sask. Canada  \n",
       "2  All residents asked to 'shelter in place' are ...  \n",
       "3  13,000 people receive #wildfires evacuation or...  \n",
       "4  Just got sent this photo from Ruby #Alaska as ...  "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10876.000000</td>\n",
       "      <td>10789</td>\n",
       "      <td>7238</td>\n",
       "      <td>7613.00000</td>\n",
       "      <td>10876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>221</td>\n",
       "      <td>4521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>catastrophic</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11-Year-Old Boy Charged With Manslaughter of T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>141</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5437.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.42966</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3139.775098</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.49506</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2718.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5437.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8156.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10875.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id       keyword location      target  \\\n",
       "count   10876.000000         10789     7238  7613.00000   \n",
       "unique           NaN           221     4521         NaN   \n",
       "top              NaN  catastrophic      USA         NaN   \n",
       "freq             NaN            50      141         NaN   \n",
       "mean     5437.500000           NaN      NaN     0.42966   \n",
       "std      3139.775098           NaN      NaN     0.49506   \n",
       "min         0.000000           NaN      NaN     0.00000   \n",
       "25%      2718.750000           NaN      NaN     0.00000   \n",
       "50%      5437.500000           NaN      NaN     0.00000   \n",
       "75%      8156.250000           NaN      NaN     1.00000   \n",
       "max     10875.000000           NaN      NaN     1.00000   \n",
       "\n",
       "                                                     text  \n",
       "count                                               10876  \n",
       "unique                                              10678  \n",
       "top     11-Year-Old Boy Charged With Manslaughter of T...  \n",
       "freq                                                   13  \n",
       "mean                                                  NaN  \n",
       "std                                                   NaN  \n",
       "min                                                   NaN  \n",
       "25%                                                   NaN  \n",
       "50%                                                   NaN  \n",
       "75%                                                   NaN  \n",
       "max                                                   NaN  "
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10876 entries, 0 to 3262\n",
      "Data columns (total 5 columns):\n",
      "id          10876 non-null int64\n",
      "keyword     10789 non-null object\n",
      "location    7238 non-null object\n",
      "target      7613 non-null float64\n",
      "text        10876 non-null object\n",
      "dtypes: float64(1), int64(1), object(3)\n",
      "memory usage: 509.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    4342\n",
       "1.0    3271\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10876, (10876, 5))"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.id.unique()), df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('id',inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('location',inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('keyword',inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10876 entries, 0 to 3262\n",
      "Data columns (total 2 columns):\n",
      "target    7613 non-null float64\n",
      "text      10876 non-null object\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 254.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\" }\n",
    "def contraction_(x):\n",
    "    for cont , exp in contraction_mapping.items():\n",
    "        x = re.sub(cont,exp,x)\n",
    "    return x\n",
    "\n",
    "import unicodedata\n",
    "def remove_accented_chars(x):\n",
    "    x = unicodedata.normalize('NFKD', x).encode('ascii','ignore').decode('utf-8','ignore')\n",
    "    return x\n",
    "\n",
    "#email\n",
    "regex = r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’]))\"\n",
    "\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from spacy.lang.en.stop_words import STOP_WORDS as stopwords\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def convert_to_root(x):\n",
    "    doc= nlp(x)\n",
    "    x_list=[]\n",
    "    for w in doc:\n",
    "        root = w.lemma_\n",
    "        x_list.append(root)\n",
    "    return ' '.join(x_list)\n",
    "\n",
    "\n",
    "df['text']=df['text'].apply(lambda x: x.lower() )\n",
    "df['text']=df['text'].apply(lambda x: contraction_(x))\n",
    "df['text']=df['text'].apply(lambda x : re.sub('[a-zA-Z0-9_-]*@[a-zA-Z0-9_-]+\\.com',' ', x))\n",
    "df['text']=df['text'].apply(lambda x : re.sub(regex, '', x))\n",
    "df['text']=df['text'].apply(lambda x : re.sub('[^\\w ]+','',x))\n",
    "df['text']=df['text'].apply(lambda x : re.sub('\\s{2,}',' ',x))\n",
    "df['text']=df['text'].apply(lambda x : BeautifulSoup(x,'html').get_text().strip())\n",
    "df['text']=df['text'].apply(lambda x : remove_accented_chars(x))\n",
    "df['text']=df['text'].apply(lambda x : ' '.join([w for w in x.split() if w not in stopwords]))\n",
    "df['text']=df['text'].apply(lambda x : convert_to_root(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                deeds reason earthquake allah forgive\n",
       "1                forest fire near la ronge sask canada\n",
       "2    resident ask shelter place notify officer evac...\n",
       "3    13000 people receive wildfire evacuation order...\n",
       "4    get send photo ruby alaska smoke wildfire pour...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7613, 5), (3263, 4), (10876, 2))"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_test.shape , df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv = cv.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10876, 20708)"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cv.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10876, 20708)"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cv.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "657239"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(' '.join(df['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10876, 20708)"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cv.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_clean = df_cv[:7613,:]\n",
    "df_test_clean = df_cv[7613:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train_clean\n",
    "y = df['target'].iloc[:7613]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7944845699277742"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred=lr.predict(df_test_clean)\n",
    "df_sample = pd.read_csv('sample_submission_init.csv')\n",
    "df_sample.head()\n",
    "df_sample['target'] = np.int64(df_pred)\n",
    "df_sample.to_csv('sample_submission.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TfIdfvectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tfidf=tfidf.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10876, 20708)"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tfidf.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10876, 20708)"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tfidf.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_clean = df_tfidf[:7613,:]\n",
    "df_test_clean = df_tfidf[7613:,:]\n",
    "X = df_train_clean\n",
    "y = df['target'].iloc[:7613]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7905449770190414"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "\n",
    "lr.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred=lr.predict(df_test_clean)\n",
    "df_sample = pd.read_csv('sample_submission_init.csv')\n",
    "df_sample.head()\n",
    "df_sample['target'] = np.int64(df_pred)\n",
    "df_sample.to_csv('sample_submission.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiple models\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name of the model ------- -- R2 score ------------ MSE------------- Time taken\n",
      " KNN                    0.7728168089297439               1\n",
      " XGB                     0.762967826657912               1\n",
      " Logistic               0.7905449770190414               0\n",
      " ADAboost               0.7347340774786605               4\n",
      " DecisionTree             0.7137229152987524               1\n",
      " RandomForest             0.7774130006565988              60\n"
     ]
    }
   ],
   "source": [
    "from  datetime import datetime\n",
    "start_time = int(datetime.now().strftime('%H%M%S'))\n",
    "\n",
    "models = []\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('XGB',XGBClassifier()))\n",
    "models.append(('Logistic',LogisticRegression()))\n",
    "models.append(('ADAboost',AdaBoostClassifier()))\n",
    "models.append(('DecisionTree', DecisionTreeClassifier()))\n",
    "models.append(('RandomForest', RandomForestClassifier()))\n",
    "\n",
    "\n",
    "import time \n",
    "\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "\n",
    "print(f'Name of the model ------- -- R2 score ------------ MSE------------- Time taken')\n",
    "\n",
    "for name, model in models:\n",
    "    model.fit(X_train,y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    res = accuracy_score(y_test, y_pred)\n",
    "     \n",
    "   # mse = mean_squared_error(y_test, y_pred)\n",
    "    #results.append((name,res,mse))\n",
    "    \n",
    "    \n",
    "    current_time = int(datetime.now().strftime('%H%M%S'))\n",
    "    time_taken = current_time - start_time\n",
    "    start_time = current_time \n",
    "    \n",
    "    print( f' {name:10} {res:30} {time_taken:15}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7905449770190414"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "\n",
    "lr.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred=lr.predict(df_test_clean)\n",
    "df_sample = pd.read_csv('sample_submission_init.csv')\n",
    "df_sample.head()\n",
    "df_sample['target'] = np.int64(df_pred)\n",
    "df_sample.to_csv('sample_submission.csv', index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp= spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp('I am living in city.').vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['vec'] = df['text'].apply(lambda x : nlp(x).vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10876,)"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['vec'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df['vec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10876,)"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate(X).reshape(-1, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10876, 300)"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_clean = X[:7613,:]\n",
    "df_test_clean = X[7613:,:]\n",
    "X = df_train_clean\n",
    "y = df['target'].iloc[:7613]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name of the model ------- -- R2 score ------------ MSE------------- Time taken\n",
      " KNN                    0.7760998030203545              14\n",
      " XGB                    0.7971109652002626              51\n",
      " Logistic               0.8063033486539725               0\n",
      " ADAboost               0.7662508207485227              25\n",
      " DecisionTree             0.6789231779382797               5\n",
      " RandomForest              0.799080761654629              16\n"
     ]
    }
   ],
   "source": [
    "from  datetime import datetime\n",
    "start_time = int(datetime.now().strftime('%H%M%S'))\n",
    "\n",
    "models = []\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('XGB',XGBClassifier()))\n",
    "models.append(('Logistic',LogisticRegression()))\n",
    "models.append(('ADAboost',AdaBoostClassifier()))\n",
    "models.append(('DecisionTree', DecisionTreeClassifier()))\n",
    "models.append(('RandomForest', RandomForestClassifier()))\n",
    "\n",
    "\n",
    "import time \n",
    "\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "\n",
    "print(f'Name of the model ------- -- R2 score ------------ MSE------------- Time taken')\n",
    "\n",
    "for name, model in models:\n",
    "    model.fit(X_train,y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    res = accuracy_score(y_test, y_pred)\n",
    "     \n",
    "   # mse = mean_squared_error(y_test, y_pred)\n",
    "    #results.append((name,res,mse))\n",
    "    \n",
    "    \n",
    "    current_time = int(datetime.now().strftime('%H%M%S'))\n",
    "    time_taken = current_time - start_time\n",
    "    start_time = current_time \n",
    "    \n",
    "    print( f' {name:10} {res:30} {time_taken:15}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8063033486539725"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "\n",
    "lr.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred=lr.predict(df_test_clean)\n",
    "df_sample = pd.read_csv('sample_submission_init.csv')\n",
    "df_sample.head()\n",
    "df_sample['target'] = np.int64(df_pred)\n",
    "df_sample.to_csv('sample_submission.csv', index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('C:/MyCode/GitHub/NLP/NLP - Basics/glove.6B.100d.txt', encoding='utf-8')\n",
    "counter =0\n",
    "glove_vector = {}\n",
    "for line in file:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    vectors = np.asarray(values[1:])\n",
    "    glove_vector[word] = vectors\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_length = 100\n",
    "\n",
    "def get_vec(x):\n",
    "    arr = np.zeros(vector_length)\n",
    "    text= str(x).split()\n",
    "    \n",
    "    for w in text:\n",
    "        try:\n",
    "            vec = glove_vector.get(w).astype(float)\n",
    "            arr = arr + vec\n",
    "        except:\n",
    "            pass\n",
    "    arr = arr.reshape(1,-1)[0]\n",
    "    return arr/len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['vec_glove']=df['text'].apply(lambda x : get_vec(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df.vec_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10876,)"
      ]
     },
     "execution_count": 515,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate(X).reshape(-1,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10876, 100)"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_clean = X[:7613,:]\n",
    "df_test_clean = X[7613:,:]\n",
    "X = df_train_clean\n",
    "y = df['target'].iloc[:7613]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name of the model ------- -- R2 score ------------ MSE------------- Time taken\n",
      " KNN                    0.7741300065659882               5\n",
      " XGB                    0.7931713722915299               4\n",
      " Logistic               0.7839789888378201               0\n",
      " ADAboost               0.7649376231122784               8\n",
      " DecisionTree             0.6881155613919895               2\n",
      " RandomForest             0.7931713722915299              10\n"
     ]
    }
   ],
   "source": [
    "from  datetime import datetime\n",
    "start_time = int(datetime.now().strftime('%H%M%S'))\n",
    "\n",
    "models = []\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('XGB',XGBClassifier()))\n",
    "models.append(('Logistic',LogisticRegression()))\n",
    "models.append(('ADAboost',AdaBoostClassifier()))\n",
    "models.append(('DecisionTree', DecisionTreeClassifier()))\n",
    "models.append(('RandomForest', RandomForestClassifier()))\n",
    "\n",
    "\n",
    "import time \n",
    "\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "\n",
    "print(f'Name of the model ------- -- R2 score ------------ MSE------------- Time taken')\n",
    "\n",
    "for name, model in models:\n",
    "    model.fit(X_train,y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    res = accuracy_score(y_test, y_pred)\n",
    "     \n",
    "   # mse = mean_squared_error(y_test, y_pred)\n",
    "    #results.append((name,res,mse))\n",
    "    \n",
    "    \n",
    "    current_time = int(datetime.now().strftime('%H%M%S'))\n",
    "    time_taken = current_time - start_time\n",
    "    start_time = current_time \n",
    "    \n",
    "    print( f' {name:10} {res:30} {time_taken:15}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7931713722915299"
      ]
     },
     "execution_count": 523,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg = XGBClassifier()\n",
    "xg.fit(X_train,y_train)\n",
    "\n",
    "xg.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred=xg.predict(df_test_clean)\n",
    "df_sample = pd.read_csv('sample_submission_init.csv')\n",
    "df_sample.head()\n",
    "df_sample['target'] = np.int64(df_pred)\n",
    "df_sample.to_csv('sample_submission.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
